from src.crawler.lianjia_crawler import LianJiaCrawler
from src.analysis.data_analysis import RentDataAnalyzer
import os


def ensure_directories():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    directories = ['data/raw', 'data/processed', 'output']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    print("âœ“ ç›®å½•ç»“æ„æ£€æŸ¥å®Œæˆ")


def main():
    print("=" * 60)
    print("           é“¾å®¶ç§Ÿæˆ¿ä¿¡æ¯åˆ†æç³»ç»Ÿ")
    print("=" * 60)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_directories()

    # åˆ›å»ºçˆ¬è™«å®ä¾‹å¹¶è¿è¡Œ
    crawler = LianJiaCrawler()

    print("\nğŸš€ å¼€å§‹çˆ¬å–é“¾å®¶ç§Ÿæˆ¿æ•°æ®...")
    houses = crawler.crawl_multiple_pages(1, 3)

    if houses:
        # ä¿å­˜æ•°æ®
        crawler.save_to_csv(houses)

        print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼æˆåŠŸè·å– {len(houses)} æ¡ç§Ÿæˆ¿æ•°æ®")

        # æ•°æ®åˆ†æ
        print("\n" + "=" * 50)
        print("           å¼€å§‹æ•°æ®åˆ†æ")
        print("=" * 50)

        data_file = "output/lianjia_rentals.csv"
        analyzer = RentDataAnalyzer(data_file)
        analyzer.generate_full_report()

        print("\nğŸ“ é¡¹ç›®å®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
        print("   - output/lianjia_rentals.csv (æˆ¿æºæ•°æ®)")
        print("   - output/price_analysis.html (é«˜ä»·æˆ¿æºå›¾è¡¨)")
        print("   - output/price_distribution.html (ä»·æ ¼åˆ†å¸ƒå›¾è¡¨)")
        print("   - data/raw/ (åŸå§‹æ•°æ®ç›®å½•)")
        print("   - data/processed/ (å¤„ç†åçš„æ•°æ®ç›®å½•)")
    else:
        print("âŒ æ•°æ®è·å–å¤±è´¥")


if __name__ == "__main__":
    main()